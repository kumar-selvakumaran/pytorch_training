{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1dEAqsXtxzZ5yH-k1RmO9IhuOeV_NJ4H9",
      "authorship_tag": "ABX9TyMjMM8nf5YAi8Fv834urWyO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumar-selvakumaran/pytorch_training/blob/main/NN_toys.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Notes:</h1>\n",
        "<h3>\n",
        "1.   pytorch forum says to alter parameters manually only with torch.no_grad():, but tried doing it without. : <a href=\"https://discuss.pytorch.org/t/how-to-manually-set-the-weights-in-a-two-layer-linear-model/45902\">link</a><br><br> dosent work : <br>error :\n",
        "\n",
        "```\n",
        "RuntimeError                              Traceback (most recent call last)\n",
        "\n",
        "<ipython-input-160-fbab85b2caea> in <cell line: 1>()\n",
        "----> 1 modelpart.get_parameter(\"layer.weight\")[0][0][0,1] = 0\n",
        "      2\n",
        "      3 # print_pars(modelpart)\n",
        "\n",
        "RuntimeError: a view of a leaf Variable that requires grad is being used in an in-place operation.\n",
        "```\n",
        "works only with torch.no_grad():<br>\n",
        "maybe related to doing because its not recommended to do inplace opertaions as read in the documentation<br>\n",
        "<hr>\n",
        "2.    when using multiple loss functions, to back propogate on each of them, you can just add each of the component losses to make a final loss, and do a final_loss.backward(); optimizer.step(). and this updates all the parameters according to how they contribute to each of these losses. i.e. as intended.\n",
        "<hr>\n",
        "4.   Parameters init done in nanogpt repo\n",
        "<a href=\"https://github.com/karpathy/nanoGPT/blob/master/model.py\">link</a><br>\n",
        "will help in\n",
        "convergence.\n",
        "\n",
        "<hr>\n",
        "5.   **DOUBT** : **WHY IS THIS HAPENING** :gradient descent step, not multiplying the loss with the gradient, it is doing w_new = w + (alpha * del_J_wrt_w), instead of w_new = w + (alpha * del_J_wrt_w * **J** )\n",
        "\n",
        "**CONCLUSION : UPDATE WAS NEVER  w_new = w + (alpha * del_J_wrt_w * J ). IT WAS ALWAYS SUPPOSED TO BE w_new = w + (alpha * del_J_wrt_w). WHEN WE HAVE A POLYNOMIAL LOSS FUNCTION, LIKE MSE, OR SSE, THE DERIVATIVE GIVES US A COEFFICIENT OF J. IN THESE CASES, THE MAGNITUTED OF J IS BACK-PROPAGATED**.\n",
        "<hr>"
      ],
      "metadata": {
        "id": "IEJjtUMzH4Jv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2d_uqJBoZXYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#helper functions KEEP\n",
        "#printing gradients and parameters of the model\n",
        "def print_pars(model):\n",
        "  named_pars = tuple(model.named_parameters())\n",
        "  for ind, i in enumerate(named_pars):\n",
        "    print(f\"{i[0]} parameters : {i[1][0]} | gradients : {i[1].grad}\")\n",
        "\n",
        "\n",
        "def init_pars(model):\n",
        "  with torch.no_grad():\n",
        "    for name, parameter in model.named_parameters():\n",
        "      parameter = model.get_parameter(name)\n",
        "      if \"bias\" in name:\n",
        "        parameter *= 0\n",
        "      else:\n",
        "        parameter = parameter ** 0\n",
        "      model.get_parameter(name)[0] = parameter\n"
      ],
      "metadata": {
        "id": "BktlKLAoICAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "<h3> Experiment 1: understanding the compuation graph of convolutional operator, and an optimization step </h3>\n",
        "\n",
        "<h3>- link to image with computation graph of the convolutional operator :\n",
        "\n",
        "[link](https://drive.google.com/file/d/12YDishmlx_VFfI00QXFR7CuZ4VCSpe0z/view?usp=drive_link)\n"
      ],
      "metadata": {
        "id": "TV0CDHs573-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "#helper functions KEEP\n",
        "\n",
        "#printing gradients and parameters of the model\n",
        "def print_pars(model):\n",
        "  named_pars = tuple(model.named_parameters())\n",
        "  for ind, i in enumerate(named_pars):\n",
        "    print(f\"{i[0]} parameters : {i[1][0]} | gradients : {i[1].grad}\")\n",
        "\n",
        "#initializing the weights to 1 and bias to 0\n",
        "def init_pars(model):\n",
        "  with torch.no_grad():\n",
        "    for name, parameter in model.named_parameters():\n",
        "      parameter = model.get_parameter(name)\n",
        "      if \"bias\" in name:\n",
        "        parameter *= 0\n",
        "      else:\n",
        "        parameter = parameter ** 0\n",
        "      model.get_parameter(name)[0] = parameter\n",
        "\n",
        "#model used\n",
        "model = nn.Conv1d(in_channels = 1,\n",
        "                  out_channels = 1,\n",
        "                  kernel_size = 2)\n",
        "\n",
        "#initializing model weights to 1, and bias to 0\n",
        "init_pars(model)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr = 1)\n",
        "\n",
        "model.train()\n",
        "\n",
        "\n",
        "inp = torch.ones([1,1,3])\n",
        "\n",
        "#using the same input for all iterations\n",
        "print(f\"INPUT IS ALWAYS : {inp}\\n\")\n",
        "\n",
        "for _ in range(10):\n",
        "  gt = torch.ones([1,1,2]) * 17    #results are same , regardless of the loss value\n",
        "  gt.requires_grad = True\n",
        "  print(f\"--------------------\")\n",
        "  print(f\"old parameters :\")\n",
        "  print_pars(model)\n",
        "  old_param = model.get_parameter(\"weight\")[0].clone().detach()\n",
        "  pred = model(inp)\n",
        "  print(f\"\\npred : {pred},\\n gt : {gt}\\n\")\n",
        "  lossval = (gt.sum() - pred.sum()).abs()\n",
        "  optimizer.zero_grad()\n",
        "  lossval.backward()\n",
        "  optimizer.step()\n",
        "  new_param = model.get_parameter(\"weight\")[0].clone().detach()\n",
        "  print(f\"(update check) old_param {old_param} - gradients {model.get_parameter('weight').grad} == new_params {new_param}\\n\")\n",
        "  print(f\"updated parameters:\")\n",
        "  print_pars(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq07j9IyNEck",
        "outputId": "eaa8aa48-c3cc-436d-d3c1-465c21c92602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT IS ALWAYS : tensor([[[1., 1., 1.]]])\n",
            "\n",
            "--------------------\n",
            "old parameters :\n",
            "weight parameters : tensor([[1., 1.]], grad_fn=<SelectBackward0>) | gradients : None\n",
            "bias parameters : -0.0 | gradients : None\n",
            "\n",
            "pred : tensor([[[2., 2.]]], grad_fn=<ConvolutionBackward0>),\n",
            " gt : tensor([[[17., 17.]]], requires_grad=True)\n",
            "\n",
            "(update check) old_param tensor([[1., 1.]]) - gradients tensor([[[-2., -2.]]]) == new_params tensor([[3., 3.]])\n",
            "\n",
            "updated parameters:\n",
            "weight parameters : tensor([[3., 3.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[-2., -2.]]])\n",
            "bias parameters : 2.0 | gradients : tensor([-2.])\n",
            "--------------------\n",
            "old parameters :\n",
            "weight parameters : tensor([[3., 3.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[-2., -2.]]])\n",
            "bias parameters : 2.0 | gradients : tensor([-2.])\n",
            "\n",
            "pred : tensor([[[8., 8.]]], grad_fn=<ConvolutionBackward0>),\n",
            " gt : tensor([[[17., 17.]]], requires_grad=True)\n",
            "\n",
            "(update check) old_param tensor([[3., 3.]]) - gradients tensor([[[-2., -2.]]]) == new_params tensor([[5., 5.]])\n",
            "\n",
            "updated parameters:\n",
            "weight parameters : tensor([[5., 5.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[-2., -2.]]])\n",
            "bias parameters : 4.0 | gradients : tensor([-2.])\n",
            "--------------------\n",
            "old parameters :\n",
            "weight parameters : tensor([[5., 5.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[-2., -2.]]])\n",
            "bias parameters : 4.0 | gradients : tensor([-2.])\n",
            "\n",
            "pred : tensor([[[14., 14.]]], grad_fn=<ConvolutionBackward0>),\n",
            " gt : tensor([[[17., 17.]]], requires_grad=True)\n",
            "\n",
            "(update check) old_param tensor([[5., 5.]]) - gradients tensor([[[-2., -2.]]]) == new_params tensor([[7., 7.]])\n",
            "\n",
            "updated parameters:\n",
            "weight parameters : tensor([[7., 7.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[-2., -2.]]])\n",
            "bias parameters : 6.0 | gradients : tensor([-2.])\n",
            "--------------------\n",
            "old parameters :\n",
            "weight parameters : tensor([[7., 7.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[-2., -2.]]])\n",
            "bias parameters : 6.0 | gradients : tensor([-2.])\n",
            "\n",
            "pred : tensor([[[20., 20.]]], grad_fn=<ConvolutionBackward0>),\n",
            " gt : tensor([[[17., 17.]]], requires_grad=True)\n",
            "\n",
            "(update check) old_param tensor([[7., 7.]]) - gradients tensor([[[2., 2.]]]) == new_params tensor([[5., 5.]])\n",
            "\n",
            "updated parameters:\n",
            "weight parameters : tensor([[5., 5.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[2., 2.]]])\n",
            "bias parameters : 4.0 | gradients : tensor([2.])\n",
            "--------------------\n",
            "old parameters :\n",
            "weight parameters : tensor([[5., 5.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[2., 2.]]])\n",
            "bias parameters : 4.0 | gradients : tensor([2.])\n",
            "\n",
            "pred : tensor([[[14., 14.]]], grad_fn=<ConvolutionBackward0>),\n",
            " gt : tensor([[[17., 17.]]], requires_grad=True)\n",
            "\n",
            "(update check) old_param tensor([[5., 5.]]) - gradients tensor([[[-2., -2.]]]) == new_params tensor([[7., 7.]])\n",
            "\n",
            "updated parameters:\n",
            "weight parameters : tensor([[7., 7.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[-2., -2.]]])\n",
            "bias parameters : 6.0 | gradients : tensor([-2.])\n",
            "--------------------\n",
            "old parameters :\n",
            "weight parameters : tensor([[7., 7.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[-2., -2.]]])\n",
            "bias parameters : 6.0 | gradients : tensor([-2.])\n",
            "\n",
            "pred : tensor([[[20., 20.]]], grad_fn=<ConvolutionBackward0>),\n",
            " gt : tensor([[[17., 17.]]], requires_grad=True)\n",
            "\n",
            "(update check) old_param tensor([[7., 7.]]) - gradients tensor([[[2., 2.]]]) == new_params tensor([[5., 5.]])\n",
            "\n",
            "updated parameters:\n",
            "weight parameters : tensor([[5., 5.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[2., 2.]]])\n",
            "bias parameters : 4.0 | gradients : tensor([2.])\n",
            "--------------------\n",
            "old parameters :\n",
            "weight parameters : tensor([[5., 5.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[2., 2.]]])\n",
            "bias parameters : 4.0 | gradients : tensor([2.])\n",
            "\n",
            "pred : tensor([[[14., 14.]]], grad_fn=<ConvolutionBackward0>),\n",
            " gt : tensor([[[17., 17.]]], requires_grad=True)\n",
            "\n",
            "(update check) old_param tensor([[5., 5.]]) - gradients tensor([[[-2., -2.]]]) == new_params tensor([[7., 7.]])\n",
            "\n",
            "updated parameters:\n",
            "weight parameters : tensor([[7., 7.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[-2., -2.]]])\n",
            "bias parameters : 6.0 | gradients : tensor([-2.])\n",
            "--------------------\n",
            "old parameters :\n",
            "weight parameters : tensor([[7., 7.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[-2., -2.]]])\n",
            "bias parameters : 6.0 | gradients : tensor([-2.])\n",
            "\n",
            "pred : tensor([[[20., 20.]]], grad_fn=<ConvolutionBackward0>),\n",
            " gt : tensor([[[17., 17.]]], requires_grad=True)\n",
            "\n",
            "(update check) old_param tensor([[7., 7.]]) - gradients tensor([[[2., 2.]]]) == new_params tensor([[5., 5.]])\n",
            "\n",
            "updated parameters:\n",
            "weight parameters : tensor([[5., 5.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[2., 2.]]])\n",
            "bias parameters : 4.0 | gradients : tensor([2.])\n",
            "--------------------\n",
            "old parameters :\n",
            "weight parameters : tensor([[5., 5.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[2., 2.]]])\n",
            "bias parameters : 4.0 | gradients : tensor([2.])\n",
            "\n",
            "pred : tensor([[[14., 14.]]], grad_fn=<ConvolutionBackward0>),\n",
            " gt : tensor([[[17., 17.]]], requires_grad=True)\n",
            "\n",
            "(update check) old_param tensor([[5., 5.]]) - gradients tensor([[[-2., -2.]]]) == new_params tensor([[7., 7.]])\n",
            "\n",
            "updated parameters:\n",
            "weight parameters : tensor([[7., 7.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[-2., -2.]]])\n",
            "bias parameters : 6.0 | gradients : tensor([-2.])\n",
            "--------------------\n",
            "old parameters :\n",
            "weight parameters : tensor([[7., 7.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[-2., -2.]]])\n",
            "bias parameters : 6.0 | gradients : tensor([-2.])\n",
            "\n",
            "pred : tensor([[[20., 20.]]], grad_fn=<ConvolutionBackward0>),\n",
            " gt : tensor([[[17., 17.]]], requires_grad=True)\n",
            "\n",
            "(update check) old_param tensor([[7., 7.]]) - gradients tensor([[[2., 2.]]]) == new_params tensor([[5., 5.]])\n",
            "\n",
            "updated parameters:\n",
            "weight parameters : tensor([[5., 5.]], grad_fn=<SelectBackward0>) | gradients : tensor([[[2., 2.]]])\n",
            "bias parameters : 4.0 | gradients : tensor([2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(inp)"
      ],
      "metadata": {
        "id": "7UdVrHiED00p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "<h3> Experiment 2: multiple heads, and loss functions </h3>\n",
        "\n",
        "<h3>- link to image with computation graph of multple loss functions :\n",
        "\n",
        "[link](https://drive.google.com/file/d/1CAHbP0r1m_LHgJ8ASeCQb2Axug049RdF/view?usp=drive_link)\n",
        "\n"
      ],
      "metadata": {
        "id": "7Ok60lFceDg0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AJhXjjfwzQI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class convlayer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(convlayer, self).__init__()\n",
        "    self.layer = nn.Conv2d(in_channels = 1,\n",
        "                           out_channels = 1,\n",
        "                           kernel_size = 2)\n",
        "  def forward(self, x):\n",
        "    return self.layer(x)\n",
        "\n",
        "\n",
        "class toynn(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    conv1 = convlayer()\n",
        "    self.conv1 = conv1\n",
        "\n",
        "    leaf1 = convlayer()\n",
        "    self.leaf1 = leaf1\n",
        "\n",
        "    leaf2 = convlayer()\n",
        "    self.leaf2 = leaf2\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x1 = self.leaf1(x)\n",
        "    x2 = self.leaf2(x)\n",
        "    ypred = torch.cat((x1, x2), axis = 0)\n",
        "    return ypred\n",
        "\n",
        "\n",
        "\n",
        "x = torch.ones((1,1,3,3))\n",
        "model = toynn()\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.get_parameter(\"leaf1.layer.weight\")[0][0][0,0] = 1\n",
        "  model.get_parameter(\"leaf1.layer.bias\")[0] = 0\n",
        "  model.get_parameter(\"leaf1.layer.weight\")[0][0][1,0] = 1\n",
        "  model.get_parameter(\"leaf1.layer.weight\")[0][0][0,1] = 1\n",
        "  model.get_parameter(\"leaf1.layer.weight\")[0][0][1,1] = 1\n",
        "\n",
        "  model.get_parameter(\"leaf2.layer.weight\")[0][0][0,0] = 1\n",
        "  model.get_parameter(\"leaf2.layer.bias\")[0] = 0\n",
        "  model.get_parameter(\"leaf2.layer.weight\")[0][0][1,0] = 1\n",
        "  model.get_parameter(\"leaf2.layer.weight\")[0][0][0,1] = 1\n",
        "  model.get_parameter(\"leaf2.layer.weight\")[0][0][1,1] = 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  model.get_parameter(\"conv1.layer.weight\")[0][0][0,0] = 1\n",
        "  model.get_parameter(\"conv1.layer.bias\")[0] = 0\n",
        "  model.get_parameter(\"conv1.layer.weight\")[0][0][1,0] = 1\n",
        "  model.get_parameter(\"conv1.layer.weight\")[0][0][0,1] = 1\n",
        "  model.get_parameter(\"conv1.layer.weight\")[0][0][1,1] = 1\n",
        "\n",
        "y = model(x)\n",
        "print(y)\n",
        "\n",
        "def ownloss(gt, pred):\n",
        "  return gt - pred\n",
        "\n",
        "def ownloss2(gt, pred):\n",
        "  return -(gt @ pred)\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\n",
        "\n",
        "model.train()\n",
        "\n",
        "gt = torch.tensor([[[17.0]], [[3.0]]])\n",
        "gt.requires_grad = True\n",
        "\n",
        "lossval1 = ownloss(gt[0],y[0])\n",
        "lossval2 = ownloss2(gt[1],y[1])\n",
        "# lossval1.backward(retain_graph = True)\n",
        "# lossval2.backward()\n",
        "lv = lossval1+lossval2\n",
        "lv.backward()\n",
        "optimizer.step()\n",
        "print_pars(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "<h3>Experiment 3 : Feature pyramid networks toy</h1>"
      ],
      "metadata": {
        "id": "G4nyvwLofI7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "\n",
        "class layer_block(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(layer_block, self).__init__()\n",
        "    self.block = nn.Conv2d(in_channels = 1,\n",
        "                           out_channels = 1,\n",
        "                           kernel_size = 2,\n",
        "                           stride = 2)\n",
        "    self.output = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.block(x)\n",
        "    self.output = output\n",
        "    print(f\"\\noutput : \\n\\n{output}\\n\")\n",
        "    return output\n",
        "\n",
        "class toyfpn(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(toyfpn, self).__init__()\n",
        "\n",
        "    self.topdown1 = layer_block()\n",
        "    self.topdown2 = layer_block()\n",
        "    self.topdown3 = layer_block()\n",
        "\n",
        "  def upsample(self, x, mode = 'bilinear'):\n",
        "    x = upsampled = nn.functional.interpolate(input = x,\n",
        "                                              scale_factor = (2,2),\n",
        "                                              mode = mode\n",
        "                                              )\n",
        "    return x\n",
        "\n",
        "  def forward(self, x):\n",
        "    outputs = tuple()\n",
        "    print(f\"\\n(TOP DOWN)\\n\")\n",
        "    print(f\"\\ninput : \\n\\n{x}\\n\")\n",
        "    x = self.topdown1(x)\n",
        "    x = self.topdown2(x)\n",
        "    x = self.topdown3(x)\n",
        "\n",
        "    outputs += tuple([x])\n",
        "\n",
        "    print(f\"\\n(BOTTOM UP) \\n\")\n",
        "    x = self.upsample(x)\n",
        "\n",
        "    print(f\"\\n upsampled data : \\n\\n{x}, \\n\\n cross data : \\n\\n{self.topdown2.output}\\n\")\n",
        "\n",
        "    x += self.topdown2.output\n",
        "\n",
        "    outputs += tuple([x])\n",
        "\n",
        "    x = self.upsample(x)\n",
        "\n",
        "    print(f\"\\n upsampled data : \\n\\n{x}, \\n\\n cross data : \\n\\n{self.topdown1.output}\")\n",
        "\n",
        "    x += self.topdown1.output\n",
        "\n",
        "    outputs += tuple([x])\n",
        "\n",
        "    print(f\"\\n(OUTPUTS) : \\n\\n {outputs}\\n\")\n",
        "    return outputs\n",
        "\n",
        "\n",
        "model = toyfpn()\n",
        "\n",
        "init_pars(model)\n",
        "\n",
        "x = torch.ones((1,1,8,8))\n",
        "\n",
        "pred = model(x)"
      ],
      "metadata": {
        "id": "Blo_k4uHHutp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_pars(model)"
      ],
      "metadata": {
        "id": "wvHRXtRNET94"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}